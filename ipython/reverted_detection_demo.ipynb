{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic damage detection in Wikipedia\n",
    "This notebook demonstrates the basic contruction of a vandalism classification system using the [revscoring](http://pythonhosted.org/revscoring/) library that we have developed specifically for classification models of MediaWiki stuff.\n",
    "\n",
    "The basic process that we'll follow is this:\n",
    "\n",
    "1. Gather example of human judgement applied to Wikipedia edits.  In this case, we'll take advantage of [reverts](https://meta.wikimedia.org/wiki/Research:Revert).  \n",
    "2. Split the data into a training and testing set\n",
    "3. Training the machine learning model\n",
    "4. Testing the machine learning model\n",
    "\n",
    "And then we'll have some fun applying the model to some edits using RCStream.  The following diagram gives a good sense for the whole process of training and evaluating a model.\n",
    "\n",
    "<img style=\"text-align: center;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Supervised_machine_learning_in_a_nutshell.svg/640px-Supervised_machine_learning_in_a_nutshell.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting labeled observations\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Machine_learning_nutshell_--_Gather_labeled_observations.svg/300px-Machine_learning_nutshell_--_Gather_labeled_observations.svg.png\" />\n",
    "\n",
    "Regretfully, running SQL queries isn't something we can do directly from the notebook *yet*.  So, we'll use [Quarry](https://quarry.wmflabs.org) to generate a nice random sample of edits.  20,000 observations should do just fine.  Here's the query I want to run:\n",
    "\n",
    "```SQL\n",
    "USE enwiki_p;\n",
    "SELECT rev_id \n",
    "FROM revision \n",
    "WHERE rev_timestamp BETWEEN \"20150201\" AND \"20160201\" \n",
    "ORDER BY RAND() \n",
    "LIMIT 20000;\n",
    "```\n",
    "\n",
    "See http://quarry.wmflabs.org/query/7530.  By clicking around the UI, I can see that this URL will download my tab-separated file: http://quarry.wmflabs.org/run/65415/output/0/tsv?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magical ipython notebook stuff puts the result of this command into a variable\n",
    "revids_f = !wget http://quarry.wmflabs.org/run/65415/output/0/tsv?download=true -qO- \n",
    "\n",
    "revids = [int(line) for line in revids_f[1:]]\n",
    "len(revids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  Now that we have a set of revisions, we need to label them.  In this case, we're going to label them as reverted/not.  We want to exclude a few different types of reverts -- e.g. when a user reverts themself or when an edit is reverted back to by someone else.  For this, we'll use the [mwreverts](https://pythonhosted.org/mwreverts) and [mwapi](https://pythonhosted.org/mwapi) libraries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...............r...."
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "import mwreverts.api\n",
    "import mwapi\n",
    "\n",
    "# We'll use the mwreverts API check.  In order to do that, we need an API session\n",
    "session = mwapi.Session(\"https://en.wikipedia.org\", \n",
    "                        user_agent=\"Revert detection demo <ahalfaker@wikimedia.org>\")\n",
    "\n",
    "# For each revision, find out if it was \"reverted\" and label it so.\n",
    "rev_reverteds = []\n",
    "for rev_id in revids[:20]:  # NOTE: Limiting to the first 20!!!!\n",
    "    try:\n",
    "        _, reverted, reverted_to = mwreverts.api.check(\n",
    "            session, rev_id, radius=5,  # most reverts within 5 edits\n",
    "            window=48*60*60,  # 2 days\n",
    "            rvprop={'user', 'ids'})  # Some properties we'll make use of\n",
    "    except (RuntimeError, KeyError) as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    if reverted is not None:\n",
    "        reverted_doc = [r for r in reverted.reverteds\n",
    "                        if r['revid'] == rev_id][0]\n",
    "\n",
    "        if 'user' not in reverted_doc or 'user' not in reverted.reverting:\n",
    "            continue\n",
    "\n",
    "        # self-reverts\n",
    "        self_revert = \\\n",
    "            reverted_doc['user'] == reverted.reverting['user']\n",
    "        \n",
    "        # revisions that are reverted back to by others\n",
    "        reverted_back_to = \\\n",
    "            reverted_to is not None and \\\n",
    "            'user' in reverted_to.reverting and \\\n",
    "            reverted_doc['user'] != \\\n",
    "            reverted_to.reverting['user']\n",
    "        \n",
    "        # If we are reverted, not by self or reverted back to by someone else, \n",
    "        # then, let's assume it was damaging.\n",
    "        damaging_reverted = not (self_revert or reverted_back_to)\n",
    "    else:\n",
    "        damaging_reverted = False\n",
    "\n",
    "    rev_reverteds.append((rev_id, damaging_reverted))\n",
    "    sys.stderr.write(\"r\" if damaging_reverted else \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  This takes too long.  You get the idea.  So, I uploaded dataset that has already been labeled here @ `../datasets/demo/enwiki.rev_reverted.20k_2015.tsv.bz2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19868"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_reverteds_f = !bzcat ../datasets/demo/enwiki.rev_reverted.20k_2015.tsv.bz2\n",
    "rev_reverteds = [line.strip().split(\"\\t\") for line in rev_reverteds_f[1:]]\n",
    "rev_reverteds = [(int(rev_id), reverted == \"True\") for rev_id, reverted in rev_reverteds]\n",
    "len(rev_reverteds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  It looks like we got an error when trying to extract the reverted status of ~132 edits, which is an acceptable loss.  Now just to make sure we haven't gone crazy, let's check some of the reverted edits:\n",
    "\n",
    "* https://en.wikipedia.org/wiki/?diff=695071713 (section blanking)\n",
    "* https://en.wikipedia.org/wiki/?diff=667375206 (unexplained addition of nonsense)\n",
    "* https://en.wikipedia.org/wiki/?diff=670204366 (vandalism \"I don't know\")\n",
    "* https://en.wikipedia.org/wiki/?diff=680329354 (adds non-existent category)\n",
    "* https://en.wikipedia.org/wiki/?diff=668682186 (test edit -- removes punctuation)\n",
    "* https://en.wikipedia.org/wiki/?diff=666882037 (adds spamlink)\n",
    "* https://en.wikipedia.org/wiki/?diff=663302354 (adds nonsense special char)\n",
    "* https://en.wikipedia.org/wiki/?diff=675803278 (unconstructive link changes)\n",
    "* https://en.wikipedia.org/wiki/?diff=680203994 (vandalism -- \"Pepe meme\")\n",
    "* https://en.wikipedia.org/wiki/?diff=656734057 (\"JELENAS BOOTY UNDSO\")\n",
    "\n",
    "OK.  Looks like we are doing pretty good. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Split the data into a training and testing set\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Machine_learning_nutshell_--_Split_into_train-test_set.svg/320px-Machine_learning_nutshell_--_Split_into_train-test_set.svg.png\" />\n",
    "Before we move on with training, it's important that we hold back some of the data for testing later.  If we train on the same data we'll test with, we risk [overfitting](https://en.wikipedia.org/wiki/Overfitting) and not noticing!\n",
    "\n",
    "In this section, we'll both split the training and testing set *and* gather prective features for each of the labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 15000\n",
      "testing: 4868\n"
     ]
    }
   ],
   "source": [
    "train_set = rev_reverteds[:15000]\n",
    "test_set = rev_reverteds[15000:]\n",
    "print(\"training:\", len(train_set))\n",
    "print(\"testing:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  In order to train the machine learning model, we'll need to give it a source of signal.  This is where \"features\" come into play.  A feature represents a simple numerical statistic that we can extract from our observations that we think will be *predictive* of our outcome.  Luckily, `revscoring` provides a whole suite of features that work well for damage detection.  In this case, we'll be looking at features of the edit diff.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awight/venv/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from revscoring.features import wikitext, revision_oriented, temporal\n",
    "from revscoring.languages import english\n",
    "\n",
    "features = [\n",
    "    # Catches long key mashes like kkkkkkkkkkkk\n",
    "    wikitext.revision.diff.longest_repeated_char_added,\n",
    "    # Measures the size of the change in added words\n",
    "    wikitext.revision.diff.words_added,\n",
    "    # Measures the size of the change in removed words\n",
    "    wikitext.revision.diff.words_removed,\n",
    "    # Measures the proportional change in \"badwords\"\n",
    "    english.badwords.revision.diff.match_prop_delta_sum,\n",
    "    # Measures the proportional change in \"informals\"\n",
    "    english.informals.revision.diff.match_prop_delta_sum,\n",
    "    # Measures the proportional change meaningful words\n",
    "    english.stopwords.revision.diff.non_stopword_prop_delta_sum,\n",
    "    # Is the user anonymous\n",
    "    revision_oriented.revision.user.is_anon,\n",
    "    # Is the user a bot or a sysop\n",
    "    revision_oriented.revision.user.in_group({'bot', 'sysop'}),\n",
    "    # How long ago did the user register?\n",
    "    temporal.revision.user.seconds_since_registration\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need to turn to `revscoring`s feature extractor to help us get us feature values for each revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/?diff=695071713\n",
      "[1, 0.0, 10839.0, -1.0, -2.5476190476190474, -1460.284567397068, True, False, 0]\n",
      "https://en.wikipedia.org/wiki/?diff=667375206\n",
      "[1, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, False, False, 9844289]\n"
     ]
    }
   ],
   "source": [
    "from revscoring.extractors import api\n",
    "api_extractor = api.Extractor(session)\n",
    "\n",
    "revisions = [695071713, 667375206]\n",
    "for rev_id in revisions:\n",
    "    print(\"https://en.wikipedia.org/wiki/?diff={0}\".format(rev_id))\n",
    "    print(list(api_extractor.extract(rev_id, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...................."
     ]
    }
   ],
   "source": [
    "# Now for the whole set!\n",
    "training_features_reverted = []\n",
    "for rev_id, reverted in train_set[:20]:\n",
    "    try:\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "        observation = {\"rev_id\": rev_id, \"cache\": feature_values, \"reverted\": reverted}\n",
    "    except RuntimeError as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    sys.stderr.write(\".\")\n",
    "    training_features_reverted.append(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to regenerate the observations file.\n",
    "#import bz2\n",
    "#from revscoring.utilities.util import dump_observation\n",
    "#\n",
    "#f = bz2.open(\"../datasets/demo/enwiki.features_reverted.training.20k_2015.json.bz2\", \"wt\")\n",
    "#for observation in training_features_reverted:\n",
    "#    dump_observation(observation, f)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  Again this takes too long, so again, I uploaded a dataset with features already extracted @ `../datasets/demo/enwiki.features_reverted.training.20k_2015.tsv.bz2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from revscoring.utilities.util import read_observations\n",
    "training_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.training.20k_2015.json.bz2\n",
    "training_features_reverted = list(read_observations(training_features_reverted_f))\n",
    "len(training_features_reverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the model\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Machine_learning_nutshell_--_Train_a_machine_learning_model.svg/320px-Machine_learning_nutshell_--_Train_a_machine_learning_model.svg.png\" />\n",
    "\n",
    "Now that we have a set of features extracted for our training set, it's time to train a model.  `revscoring` provides a set of different classifier algorithms.  From past experience, I know a [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) classifier works well, so we'll use that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seconds_elapsed': 0.48470592498779297}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from revscoring.scoring.models import GradientBoosting\n",
    "is_reverted = GradientBoosting(features, labels=[True, False], version=\"live demo!\", \n",
    "                               learning_rate=0.01, max_features=\"log2\", \n",
    "                               n_estimators=700, max_depth=5,\n",
    "                               population_rates={False: 0.5, True: 0.5}, scale=True, center=True)\n",
    "\n",
    "training_unpacked = [(o[\"cache\"], o[\"reverted\"]) for o in training_features_reverted]\n",
    "is_reverted.train(training_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that we can play around with.  Let's try a few edits from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True https://en.wikipedia.org/wiki/?diff=699665317 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=683832871 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=653913156 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=654545786 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=670608733 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=689399141 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=662365029 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=656782076 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=698954388 False 0.0\n",
      "True https://en.wikipedia.org/wiki/?diff=645603577 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=687073859 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=665341163 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=654524549 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=682425664 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=674780271 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=684793059 False 0.0\n",
      "False https://en.wikipedia.org/wiki/?diff=655583788 False 0.0\n"
     ]
    },
    {
     "ename": "RevisionNotFound",
     "evalue": "RevisionNotFound: Could not find revision ({revision}:700003789)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRevisionNotFound\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-186cf63e3184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrev_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_reverted_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfeature_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_reverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     print(False, \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve_many\u001b[0;34m(dependents, context, cache, profile)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdependent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdependents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         value, cache, history = _solve(dependent, context=context, cache=cache,\n\u001b[0;32m--> 269\u001b[0;31m                                        profile=profile)\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/dependent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                      .format(self, self.calls))\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/extractors/api/datasources.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, rev_id, dependents)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrev_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrev_doc_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRevisionNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrev_doc_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRevisionNotFound\u001b[0m: RevisionNotFound: Could not find revision ({revision}:700003789)"
     ]
    }
   ],
   "source": [
    "reverted_obs = [rev_id for rev_id, reverted in test_set if reverted]\n",
    "non_reverted_obs = [rev_id for rev_id, reverted in test_set if not reverted]\n",
    "\n",
    "for rev_id in reverted_obs[:10]:\n",
    "    feature_values = list(api_extractor.extract(rev_id, features))\n",
    "    score = is_reverted.score(feature_values)\n",
    "    print(True, \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "          score['prediction'], round(score['probability'][True], 2))\n",
    "\n",
    "for rev_id in non_reverted_obs[:10]:\n",
    "    feature_values = list(api_extractor.extract(rev_id, features))\n",
    "    score = is_reverted.score(feature_values)\n",
    "    print(False, \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "          score['prediction'], round(score['probability'][True], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing the model\n",
    "So, the above analysis can help give us a sense for whether the model is working or not, but it's hard to standardize between models.  So, we can apply some metrics that are specially crafted for machine learning models.  \n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Machine_learning_nutshell_--_Test_the_machine_learning_model.svg/640px-Machine_learning_nutshell_--_Test_the_machine_learning_model.svg.png\" />\n",
    "</center>\n",
    "\n",
    "But first, I'll need to load the pre-generated feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.testing.20k_2015.json.bz2\n",
    "testing_features_reverted = list(read_observations(testing_features_reverted_f))\n",
    "testing_unpacked = [(o[\"cache\"], o[\"reverted\"]) for o in testing_features_reverted]\n",
    "len(testing_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision) -- The proportion of correct predictions\n",
    "* [Precision](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of correct positive predictions\n",
    "* [Recall](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of positive examples predicted as positive\n",
    "* Filter rate at 90% recall -- The proportion of observations that can be ignored while still catching 90% of \"reverted\" edits.  \n",
    "\n",
    "We'll use `revscoring` statistics to measure these against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Information:\n",
      "\t - type: GradientBoosting\n",
      "\t - version: live demo!\n",
      "\t - params: {'random_state': None, 'max_features': 'log2', 'max_depth': 5, 'min_impurity_decrease': 0.0, 'scale': True, 'init': None, 'min_samples_leaf': 1, 'min_impurity_split': None, 'verbose': 0, 'center': True, 'criterion': 'friedman_mse', 'multilabel': False, 'min_samples_split': 2, 'max_leaf_nodes': None, 'population_rates': None, 'subsample': 1.0, 'labels': [True, False], 'loss': 'deviance', 'n_estimators': 700, 'warm_start': False, 'min_weight_fraction_leaf': 0.0, 'presort': 'auto', 'label_weights': None, 'learning_rate': 0.01}\n",
      "\tEnvironment:\n",
      "\t - revscoring_version: '2.2.2'\n",
      "\t - platform: 'Linux-4.16.0-x86_64-with-debian-9.4'\n",
      "\t - machine: 'x86_64'\n",
      "\t - version: '#1 SMP Wed Apr 18 14:02:11 PDT 2018'\n",
      "\t - system: 'Linux'\n",
      "\t - processor: ''\n",
      "\t - python_build: ('default', 'Jan 19 2017 14:11:04')\n",
      "\t - python_compiler: 'GCC 6.3.0 20170118'\n",
      "\t - python_branch: ''\n",
      "\t - python_implementation: 'CPython'\n",
      "\t - python_revision: ''\n",
      "\t - python_version: '3.5.3'\n",
      "\t - release: '4.16.0'\n",
      "\t\n",
      "\tStatistics:\n",
      "\tcounts (n=20):\n",
      "\t\tlabel      n         ~True    ~False\n",
      "\t\t-------  ---  ---  -------  --------\n",
      "\t\tTrue       1  -->        1         0\n",
      "\t\tFalse     19  -->        0        19\n",
      "\trates:\n",
      "\t\t              True    False\n",
      "\t\t----------  ------  -------\n",
      "\t\tsample        0.05     0.95\n",
      "\t\tpopulation    0.5      0.5\n",
      "\tmatch_rate (micro=0.5, macro=0.5):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t    0.5     0.5\n",
      "\tfilter_rate (micro=0.5, macro=0.5):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t    0.5     0.5\n",
      "\trecall (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\t!recall (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\tprecision (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\t!precision (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\tf1 (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\t!f1 (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\taccuracy (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\tfpr (micro=0.0, macro=0.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      0       0\n",
      "\troc_auc (micro=1.0, macro=1.0):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t      1       1\n",
      "\tpr_auc (micro=0.995, macro=0.995):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.995   0.995\n",
      "\t\n",
      "\t - score_schema: {'type': 'object', 'properties': {'probability': {'type': 'object', 'description': 'A mapping of probabilities onto each of the potential output labels', 'properties': {'true': 'number', 'false': 'number'}}, 'prediction': {'type': 'bool', 'description': 'The most likely label predicted by the estimator'}}, 'title': 'Scikit learn-based classifier score with probability'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_reverted.test(testing_unpacked)\n",
    "\n",
    "print(is_reverted.info.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus round!  Let's listen to Wikipedia's vandalism!\n",
    "\n",
    "So we don't have the most powerful damage detection classifier, but then again, we're only including 9 features.  Usually we run with ~60 features and get to much higher levels of fitness.  *but* this model is still useful and it should help us detect the most egregious vandalism in Wikipedia.  In order to listen to Wikipedia, we'll need to connect to [RCStream](https://wikitech.wikimedia.org/wiki/RCStream) -- the same live feed that powers [listen to Wikipedia](http://listen.hatnote.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good edit https://en.wikipedia.org/wiki/?diff=672754993 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754994 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754995 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=4291051 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754996 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754997 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754999 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=672754998 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=92413625 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-1868e2b57ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mrev_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mfeature_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_reverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve_many\u001b[0;34m(dependents, context, cache, profile)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdependent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdependents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         value, cache, history = _solve(dependent, context=context, cache=cache,\n\u001b[0;32m--> 269\u001b[0;31m                                        profile=profile)\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m    236\u001b[0m                                                \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                                profile=profile)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(dependent, context, cache, history, profile)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/dependencies/dependent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                      .format(self, self.calls))\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/revscoring/revscoring/features/wikitext/datasources/edit.py\u001b[0m in \u001b[0;36m_process_operations\u001b[0;34m(a_segments, b_segments, a, b)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_process_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0moperations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_matcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     logger.debug(\"diff() of {0} and {1} tokens took {2} seconds.\"\n\u001b[1;32m    283\u001b[0m                  .format(len(a), len(b), time.time() - start))\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/deltas/algorithms/segment_matcher.py\u001b[0m in \u001b[0;36mdiff_segments\u001b[0;34m(a_segments, b_segments)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Perform a simple LCS over unmatched tokens and clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mclustered_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_matcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_segment_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_segment_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Return the expanded (de-clustered) operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/deltas/algorithms/sequence_matcher.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m     46\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mopcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_opcodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparse_opcodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/difflib.py\u001b[0m in \u001b[0;36mget_opcodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0;31m# invariant:  we've pumped out correct diffs to change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# a[:i] into b[:j], and the next matching block is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mj2lenget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj2len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mnewj2len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# a[i] matches b[j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sseclient import SSEClient as EventSource\n",
    "\n",
    "url = 'https://stream.wikimedia.org/v2/stream/recentchange'\n",
    "for event in EventSource(url):\n",
    "    if event.event == 'message':\n",
    "        try:\n",
    "            change = json.loads(event.data)\n",
    "            if change['type'] not in ('new', 'edit'):\n",
    "                continue\n",
    "        \n",
    "            rev_id = change['revision']['new']\n",
    "            feature_values = list(api_extractor.extract(rev_id, features))\n",
    "            score = is_reverted.score(feature_values)\n",
    "            if score['prediction']:\n",
    "                print(\"!!!Please review\", \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "                      round(score['probability'][True], 2), flush=True)\n",
    "            else:\n",
    "                print(\"Good edit\", \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id),\n",
    "                      round(score['probability'][True], 2), flush=True)\n",
    "        except ValueError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
